# FindMyFlick - Python Proof of Concept

## Overview

This folder contains Python scripts used for the FindMyFlick Senior Capstone Project. There are two main types of scripts:

1. API exploration and schema mapping
   - Used to understand available fields, data types, and identifier behavior across APIs.

2. Database seed generation
   - Used to generate SQL seed files that populate the Postgres database with a repeatable starter dataset for frontend/backend development.

Primary APIs used:
- TMDB (movie metadata, credits, keywords, streaming providers)
- DoesTheDogDie (DTDD) (content warning topics and per-movie warning votes/answers)
- OMDb (supplemental metadata like ratings, etc.)

Important note about “editions”:
- The exploration work confirmed that “extended editions / director’s cuts” do not get separate TMDB movie IDs in a way that helps us treat them as separate titles. They may show up as different “watch” listings on a streaming service, but they generally do not map cleanly to separate TMDB movie records.

---

## Folder Structure

Each schema_*.py script maps a single API endpoint to document available fields, types, and sample values.

python_scripts/
├── assets/                                                    # Example outputs (markdown exports and samples)
│   ├── movie_lookup_example.png                               # Example Power BI / app output
│   ├── schema_omdb_core_fight_club.md                         # OMDb sample output for Fight Club
│   ├── schema_tmdb_credits.md                                 # TMDB /movie/{id}/credits field list
│   ├── schema_tmdb_movie_core.md                              # TMDB /movie/{id} field list
│   ├── schema_tmdb_providers.md                               # TMDB /movie/{id}/providers (US-only, flatrate or free with ads)
│   ├── schema_tmdb_release_dates.md                           # TMDB /movie/{id}/release_dates field list
│   ├── schema_tmdb_images.md                                  # TMDB /movie/{id}/images field list (posters, backdrops)
│   ├── schema_tmdb_keywords.md                                # TMDB /movie/{id}/keywords field list
│   ├── schema_tmdb_external_ids.md                            # TMDB /movie/{id}/external_ids field list (for cross-API linking)
│   ├── schema_tmdb_recommendations.md                         # TMDB /movie/{id}/recommendations (user-similarity algorithm)
│   ├── schema_tmdb_similar.md                                 # TMDB /movie/{id}/similar (metadata-similarity algorithm)
│   ├── schema_tmdb_discover.md                                # TMDB /discover/movie (filtered search / recommendation algorithm)
│   └── schema_tmdb_trending_week.md                           # TMDB /trending/movie/week (current popularity algorithm)
│
├── content_warnings/                                          # DoesTheDogDie taxonomy and processing scripts
│   ├── data/
│   │   └── dtdd/
│   │       └── dtdd_topics_catalog.json                       # Raw DoesTheDogDie topics export (200+ entries)
│   │
│   └── taxonomy/
│       ├── umbrellas.json                                     # Tier-1 umbrella categories (12 total)
│       ├── claude_taxonomy.yml                                # Tier-2 subcategories mapped to DTDD topic IDs
│       ├── structure_report.md                                # Human-readable summary + validation
│       ├── expanded.json                                      # Backend-ready taxonomy for integration
│       ├── build_structure_report.py                          # Generates structure_report.md
│       └── build_expanded_json.py                             # Generates expanded.json
│
├── dtdd/                                                      # Scripts for analyzing DoesTheDogDie API endpoints
│   └── schema_dtdd_topics_catalog.py                          # Aggregates unique topics across many sampled movies
│
├── exploration/                                               # One-off investigations and research scripts
│   ├── output/                                                # Outputs generated by exploration scripts
│   ├── __init__.py
│   ├── edition_probe_omdb.py                                  # Checks whether alternate editions have different OMDb IDs
│   ├── edition_probe_tmdb.py                                  # Checks whether alternate editions have different TMDB IDs
│   ├── extract_edition_notes_from_bundle.py                   # Extracts edition-related notes from bundled API results
│   └── README.md                                              # Notes and findings for exploration work
│
├── normalization/                                             # TMDB and related normalization scripts and outputs
│   ├── data/
│   │   └── tmdb/
│   │       ├── services_us_tiered.json                        # Streaming providers grouped by monetization tier (subscription, free_with_ads, rent, buy)
│   │       └── genres.json                                    # Unified genre dictionary (movie + TV, with union and byId mappings)
│   │
│   └── scripts/
│       ├── build_tmdb_us_tiered_providers.py                  # Builds U.S. provider tiers
│       └── build_tmdb_genres.py                               # Builds combined genre dictionary
│
├── omdb/                                                      # Scripts for analyzing OMDb API endpoint
│   └── schema_omdb_core.py                                    # Core movie metadata including MPAA rating, year, and language
│
├── prototypes/                                                # Experimental scripts (not part of the standard seed workflow)
│   └── (varies)                                               # Keep anything here as "nice-to-have" experiments
│
├── seed/                                                      # Seed SQL generators for database population
│   ├── __init__.py
│   ├── seed_dtdd_media_map_for_seeded_movies_to_sql.py        # Builds movie_dtdd_titles mapping (imdb -> dtdd_media_id)
│   ├── seed_dtdd_topics_to_sql.py                             # Seeds warnings/topics catalog from DTDD
│   ├── seed_dtdd_warnings_for_seeded_movies_to_sql.py         # Seeds per-movie warning answers from DTDD
│   ├── seed_tmdb_collections_for_seeded_movies_to_sql.py      # Seeds collections + movie_collections from TMDB
│   ├── seed_tmdb_genres_for_seeded_movies_to_sql.py           # Seeds movie_genres from TMDB
│   ├── seed_tmdb_keywords_for_seeded_movies_to_sql.py         # Seeds keywords + movie_keywords from TMDB
│   ├── seed_tmdb_people_for_seeded_movies_to_sql.py           # Seeds people + credits from TMDB
│   ├── seed_us_popular_100_movies_to_sql.py                   # Seeds base movie list (starter dataset)
│   ├── seed_us_watch_providers_for_seeded_movies_to_sql.py    # Seeds streaming providers (US only)
│   └── seed_warnings_from_catalog_to_sql.py                   # Seeds warning catalog into Postgres
│
├── shared/                                                    # Shared helpers for fetching, flattening, and scoping API data
│   ├── constants.py                                           # Language and region defaults (US market, English text)
│   └── schema_utils.py                                        # Flatten JSON and export markdown tables
│
├── tmdb/                                                      # Scripts for analyzing TMDB API endpoints
│   ├── schema_tmdb_credits.py                                 # Actors, directors, and crew members
│   ├── schema_tmdb_movie_core.py                              # General movie info (poster path, release date, genre, etc.)
│   ├── schema_tmdb_providers.py                               # Paid subscription and ad-supported streaming providers (US-only)
│   ├── schema_tmdb_release_dates.py                           # Full release date info including region and certification
│   ├── schema_tmdb_images.py                                  # Image metadata (posters, backdrops)
│   ├── schema_tmdb_keywords.py                                # Movie keywords and tags
│   ├── schema_tmdb_external_ids.py                            # External identifiers (IMDb, Facebook, Instagram, Twitter)
│   │
│   ├── algorithm_tmdb_recommendations.py                      # User-similarity recommendation engine
│   ├── algorithm_tmdb_similar.py                              # Metadata-similarity recommendation engine
│   ├── algorithm_tmdb_discover.py                             # Filtered search / hybrid recommendation system
│   └── algorithm_tmdb_trending_week.py                        # Current popularity algorithm
│
├── .env.template                                              # Environment variable template (copy to project root as .env)
└── README.md                                                  # This file
```

---

## How to Use This Repo

This repo has two main kinds of Python scripts:

1. Exploration / schema scripts  
   - Used to inspect API endpoints and export example outputs (mostly for documentation and planning).
   - These do not populate the database.

2. Seed scripts  
   - Used to generate SQL seed files in `database/seed/` so the database can be populated consistently.
   - The generated `.sql` files are then applied using `psql`.

Most commands below assume you run them from the repo root:

- `C:\repos\FindMyFlick` (Windows)
- `~/repos/FindMyFlick` (macOS/Linux)

---

## Environment Variables

This project loads environment variables from the repo root `.env`.

Your `.env` is not committed. Use `.env.template` as a starting point if needed.

Minimum keys typically needed:

- `TMDB_API_KEY`
- `OMDB_API_KEY`
- `DTDD_API_KEY`

If you run the seed scripts that connect to Postgres, also set:

- `DB_HOST` (example: `localhost`)
- `DB_PORT` (example: `5432`)
- `DB_NAME` (example: `findmyflick`)
- `DB_USER` (example: `postgres`)
- `DB_PASS` (your local Postgres password)

Note: The seed scripts assume you are running them from the repo root so `load_dotenv(Path.cwd() / ".env")` resolves correctly.

## Setup (Part 1): prerequisites + Python environment

### Prerequisites
Install these before running anything:
- PostgreSQL (local) with `psql` available in your terminal
- Python 3.x
- Git

### Environment variables
This repo uses a `.env` file at the project root (same level as `database/` and `python_scripts/`).

Minimum keys used by the Python seed scripts:
- `DB_HOST`
- `DB_PORT`
- `DB_NAME`
- `DB_USER`
- `DB_PASS`

API keys used by scripts (as needed):
- `TMDB_API_KEY`
- `OMDB_API_KEY`
- `DTDD_API_KEY`

Example `.env` (do not commit your real file):
DB_HOST=localhost
DB_PORT=5432
DB_NAME=findmyflick
DB_USER=postgres
DB_PASS=your_postgres_password
TMDB_API_KEY=your_key
OMDB_API_KEY=your_key
DTDD_API_KEY=your_key

### Create + activate the virtual environment
From the repo root:

PowerShell:
.\.venv\Scripts\python.exe -m venv .venv
.\.venv\Scripts\Activate.ps1

### Install Python dependencies
Use pip through the venv Python:

.\.venv\Scripts\python.exe -m pip install -U pip
.\.venv\Scripts\python.exe -m pip install python-dotenv requests psycopg[binary]

Notes:
- We use `psycopg` (v3) + `psycopg[binary]` for Postgres connections in seed scripts.
- `python-dotenv` loads your root `.env` file inside scripts.

### Confirm `.env` loads
From the repo root:

python -c "from pathlib import Path; from dotenv import load_dotenv; import os; load_dotenv(Path.cwd()/'.env'); print('DB_HOST', os.getenv('DB_HOST')); print('DB_NAME', os.getenv('DB_NAME')); print('DB_USER', os.getenv('DB_USER')); print('DB_PASS set?', os.getenv('DB_PASS') is not None)"


## Setup (Part 2): build the database (schema → seed → views)

Run these from the repo root.

### 1. Create the database (if you haven’t already)
If `findmyflick` already exists, skip this step.

psql -h localhost -p 5432 -U postgres -c "CREATE DATABASE findmyflick;"

### 2. Apply schema files (creates tables, indexes, constraints)
Run the schema scripts in order:

psql -h localhost -p 5432 -U postgres -d findmyflick -f database/schema/001_init.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/schema/002_streaming_providers.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/schema/003_genres.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/schema/004_people_and_credits.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/schema/005_search_extensions_and_indexes.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/schema/006_keywords.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/schema/007_collections.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/schema/008_dtdd.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/schema/009_dtdd_match_bridge.sql

### 3. Seed baseline data (local “starter” dataset)
These are the SQL seed files under `database/seed/`.

psql -h localhost -p 5432 -U postgres -d findmyflick -f database/seed/000_seed_warnings_catalog.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/seed/001_seed_us_popular_100_movies.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/seed/002_seed_us_popular_100_movie_streaming.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/seed/003_seed_us_popular_100_movie_genres.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/seed/004_seed_us_popular_100_people_and_credits.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/seed/006_seed_us_popular_100_movie_keywords.sql
psql -h localhost -p 5432 -U postgres -d findmyflick -f database/seed/007_seed_us_popular_100_movie_collections.sql

DTDD seed files:
- 009 is generated by the Python script in step 5
- 008 is generated by the Python script in step 6

### 4. Apply views (rebuild all views in the right order)
Run the view apply script:

psql -h localhost -p 5432 -U postgres -d findmyflick -f database/views/_apply_views.sql

### 5. Optional: generate DTDD media map (movie → DTDD media id)
This hits the DTDD API and writes these files:
- database/seed/009_seed_us_streamable_dtdd_media_map.sql
- database/seed/009_seed_us_streamable_dtdd_media_map.log.json

python python_scripts/seed/seed_dtdd_media_map_for_seeded_movies_to_sql.py

Then apply the generated SQL:

psql -h localhost -p 5432 -U postgres -d findmyflick -f database/seed/009_seed_us_streamable_dtdd_media_map.sql

### 6. Optional: generate DTDD warnings for seeded movies (writes into movie_warnings)
This hits the DTDD API and writes:
- database/seed/008_seed_us_popular_100_movie_warnings.sql

python python_scripts/seed/seed_dtdd_warnings_for_seeded_movies_to_sql.py

Then apply the generated SQL:

psql -h localhost -p 5432 -U postgres -d findmyflick -f database/seed/008_seed_us_popular_100_movie_warnings.sql

---

## Content Warning Taxonomy (DoesTheDogDie)

This folder defines how DoesTheDogDie (DTDD) topics are grouped into broader categories for FindMyFlick.  
It converts over 200 individual content warnings into 12 Tier-1 *umbrella* categories with nested Tier-2 subcategories.

### Purpose
- Simplifies search and filtering for sensitive content.
- Lets users filter at either a high-level (e.g., “Animal Harm & Death”) or specific topic level.
- Provides a static JSON (`expanded.json`) that maps each DTDD topic ID to its umbrella category.

### How It Works
1. **`dtdd_topics_catalog.json`** — the raw topic list pulled from the DoesTheDogDie API.  
2. **`umbrellas.json`** — defines the 12 high-level umbrella categories.  
3. **`claude_taxonomy.yml`** — groups topic IDs under each umbrella and subcategory.  
4. **`build_structure_report.py`** — generates a readable Markdown report (`structure_report.md`) summarizing Tier-1 and Tier-2 layout.  
5. **`build_expanded_json.py`** — builds `expanded.json`, the file actually used by the backend.

### Developer Notes
If you update the taxonomy and need to rebuild outputs:
```bash
pip install pyyaml
python python_scripts/content_warnings/taxonomy/build_structure_report.py
python python_scripts/content_warnings/taxonomy/build_expanded_json.py
```

The second script writes `expanded.json`, which the backend can load like this:

```python
import json
from pathlib import Path

taxonomy = json.loads(
    Path("python_scripts/content_warnings/taxonomy/expanded.json").read_text(encoding="utf-8")
)
```

# Example lookups:
animal_ids = taxonomy["umbrella_to_topic_ids"]["U01"]
topic_name = taxonomy["topics"]["153"]["topic_name"]
umbrellas_for_topic = taxonomy["topic_id_to_umbrellas"]["153"]
This file is static and can be imported directly into backend code or used for front-end filtering logic.
---

## Example Output

- Screenshot of the demo script:
  ![Example Output](python_scripts/assets/movie_lookup_example.png)

- Markdown export of TMDB `/movie/{id}` fields:
  [schema_tmdb_movie_core.md](python_scripts/assets/schema_tmdb_movie_core.md)

---

## Data Normalization (TMDB and Related Sources)

This folder defines how **The Movie Database (TMDB)** data is normalized for *FindMyFlick*.  
It converts raw TMDB API outputs into structured JSON files that can be directly joined with other datasets such as content warnings, keywords, or recommendations.

### Purpose
- Provides consistent reference data (genres, streaming providers, etc.) for filtering and joining across APIs.  
- Uses the same `.env` configuration as other scripts, reading `TMDB_API_KEY` from the project root.  
- Follows the same structure and build process as the **DoesTheDogDie taxonomy**, keeping the codebase modular and predictable.

### Folder  
`python_scripts/normalization/`

---

### Current Outputs

| File | Description |
|------|--------------|
| `data/tmdb/services_us_tiered.json` | Canonical list of **U.S. streaming providers**, grouped into four monetization tiers: `subscription`, `free_with_ads`, `rent`, and `buy`. |
| `data/tmdb/genres.json` | Combined dictionary of **movie and TV genres**, including unified `union` keys and lookup dictionaries for `byId`, `movie`, and `tv`. |

---

### Scripts

| Script | Purpose |
|---------|----------|
| `scripts/build_tmdb_us_tiered_providers.py` | Fetches TMDB `/watch/providers` data for the U.S. region and builds tiered lists of streaming providers (`subscription`, `free_with_ads`, `rent`, `buy`). |
| `scripts/build_tmdb_genres.py` | Fetches `/genre/movie/list` and `/genre/tv/list` and merges them into a unified structure with `union` and `byId` dictionaries. |

---

### Run Instructions

#### Build Tiered Streaming Providers
Fetches data directly from TMDB using your API key in the root `.env`.

```bash
python -m python_scripts.normalization.scripts.build_tmdb_us_tiered_providers
```

Output:
```
python_scripts/normalization/data/tmdb/services_us_tiered.json
```

#### Build Genre Dictionary
Fetches both movie and TV genre lists from TMDB and combines them into a single normalized structure.

```bash
python -m python_scripts.normalization.scripts.build_tmdb_genres
```

Output:
```
python_scripts/normalization/data/tmdb/genres.json
```

---

### Future Additions
- `build_tmdb_keywords.py` → unified keyword dictionary for content-based filtering or recommendations.  
- `build_tmdb_certifications.py` → normalized movie and TV certification data for regional ratings.  
- `merge_normalization.py` → merges all normalization outputs into a single master reference for the backend.

---

### Developer Notes
- Both normalization scripts use the same lightweight `.env` loader as other proof-of-concept scripts (no additional dependencies required).  
- TMDB’s API rate limits are respected with short delays between requests.  
- All JSON outputs are static, portable, and ready for backend integration or front-end filtering.

## References

- Portions of the Python scripts were written and debugged with assistance from IntelliSense and integrated AI development tools in Visual Studio Code.
